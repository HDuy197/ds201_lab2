{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS9d5cDGirV-"
      },
      "source": [
        "# Bài 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ7XRrP7N5U1",
        "outputId": "b441c3b3-30b1-4741-9590-3f28bb89e70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_zip_path = '/content/drive/My Drive/VinaFood21.zip'\n",
        "\n",
        "!unzip -q -o \"{drive_zip_path}\" -d ./data\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DATA_DIR = './data/VinaFood21'\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "TEST_DIR = os.path.join(DATA_DIR, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZbRr8FKiu0_",
        "outputId": "6fbff3f4-2cd0-439d-ff21-b6724efd352e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lớp (NUM_CLASSES): 21\n",
            "Kích thước tập huấn luyện: 10044\n",
            "Kích thước tập test: 6682\n"
          ]
        }
      ],
      "source": [
        "input_size = 224\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "        transforms.Resize(input_size + 32),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n",
        "    'test': datasets.ImageFolder(TEST_DIR, data_transforms['test'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(image_datasets['train'], batch_size=128, shuffle=True, num_workers=2),\n",
        "    'test': DataLoader(image_datasets['test'], batch_size=128, shuffle=False, num_workers=2)\n",
        "}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(f\"Số lớp (NUM_CLASSES): {len(class_names)}\")\n",
        "print(f\"Kích thước tập huấn luyện: {dataset_sizes['train']}\")\n",
        "print(f\"Kích thước tập test: {dataset_sizes['test']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hSaSj5Xvi7DF"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "\n",
        "        self.branch1 = ConvBlock(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, ch3x3red, kernel_size=1),\n",
        "            ConvBlock(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, ch5x5red, kernel_size=1),\n",
        "            ConvBlock(ch5x5red, ch5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            ConvBlock(in_channels, pool_proj, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.conv2_1 = ConvBlock(64, 64, kernel_size=1)\n",
        "        self.conv2_2 = ConvBlock(64, 192, kernel_size=3, padding=1)\n",
        "\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nTCtqiwjQsq",
        "outputId": "f9ff76ef-f21f-480a-b483-a43487aaf3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/25], Loss: 2.5568\n",
            "Learning Rate hiện tại: 0.0001000000\n",
            "Epoch [2/25], Loss: 2.1667\n",
            "Learning Rate hiện tại: 0.0001000000\n",
            "Epoch [3/25], Loss: 2.0046\n",
            "Learning Rate hiện tại: 0.0001000000\n",
            "Epoch [4/25], Loss: 1.8942\n",
            "Learning Rate hiện tại: 0.0001000000\n",
            "Epoch [5/25], Loss: 1.7941\n",
            "Learning Rate hiện tại: 0.0000500000\n",
            "Epoch [6/25], Loss: 1.6551\n",
            "Learning Rate hiện tại: 0.0000500000\n",
            "Epoch [7/25], Loss: 1.5994\n",
            "Learning Rate hiện tại: 0.0000500000\n",
            "Epoch [8/25], Loss: 1.5214\n",
            "Learning Rate hiện tại: 0.0000500000\n",
            "Epoch [9/25], Loss: 1.4840\n",
            "Learning Rate hiện tại: 0.0000500000\n",
            "Epoch [10/25], Loss: 1.4436\n",
            "Learning Rate hiện tại: 0.0000250000\n",
            "Epoch [11/25], Loss: 1.3520\n",
            "Learning Rate hiện tại: 0.0000250000\n",
            "Epoch [12/25], Loss: 1.3158\n",
            "Learning Rate hiện tại: 0.0000250000\n",
            "Epoch [13/25], Loss: 1.2851\n",
            "Learning Rate hiện tại: 0.0000250000\n",
            "Epoch [14/25], Loss: 1.2669\n",
            "Learning Rate hiện tại: 0.0000250000\n",
            "Epoch [15/25], Loss: 1.2357\n",
            "Learning Rate hiện tại: 0.0000125000\n",
            "Epoch [16/25], Loss: 1.1907\n",
            "Learning Rate hiện tại: 0.0000125000\n",
            "Epoch [17/25], Loss: 1.1677\n",
            "Learning Rate hiện tại: 0.0000125000\n",
            "Epoch [18/25], Loss: 1.1573\n",
            "Learning Rate hiện tại: 0.0000125000\n",
            "Epoch [19/25], Loss: 1.1455\n",
            "Learning Rate hiện tại: 0.0000125000\n",
            "Epoch [20/25], Loss: 1.1345\n",
            "Learning Rate hiện tại: 0.0000062500\n",
            "Epoch [21/25], Loss: 1.0846\n",
            "Learning Rate hiện tại: 0.0000062500\n",
            "Epoch [22/25], Loss: 1.0889\n",
            "Learning Rate hiện tại: 0.0000062500\n",
            "Epoch [23/25], Loss: 1.0689\n",
            "Learning Rate hiện tại: 0.0000062500\n",
            "Epoch [24/25], Loss: 1.0670\n",
            "Learning Rate hiện tại: 0.0000062500\n",
            "Epoch [25/25], Loss: 1.0621\n",
            "Learning Rate hiện tại: 0.0000031250\n",
            "Độ chính xác (Accuracy): 57.63%\n",
            "Precision (Macro): 0.5708\n",
            "Recall (Macro): 0.5612\n",
            "F1-score (Macro): 0.5613\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")\n",
        "\n",
        "model = GoogLeNet(num_classes=21).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in dataloaders['train']:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['train']\n",
        "    print(f'Epoch [{epoch+1}/25], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Learning Rate hiện tại: {scheduler.get_last_lr()[0]:.10f}\")\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Độ chính xác (Accuracy): {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision (Macro): {precision:.4f}\")\n",
        "print(f\"Recall (Macro): {recall:.4f}\")\n",
        "print(f\"F1-score (Macro): {f1:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ri5mRLz-imM8"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
