{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Bài 3"
      ],
      "metadata": {
        "id": "awo7WpnZk4Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_zip_path = '/content/drive/My Drive/VinaFood21.zip'\n",
        "\n",
        "!mkdir -p ./data\n",
        "!unzip -q -o \"{drive_zip_path}\" -d ./data\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DATA_DIR = './data/VinaFood21'\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "TEST_DIR = os.path.join(DATA_DIR, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A8GcI5jk7WH",
        "outputId": "95f00c78-6112-4e75-ce66-0a528e3cfdc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 224\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "        transforms.Resize(input_size + 32), # 256\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n",
        "    'test': datasets.ImageFolder(TEST_DIR, data_transforms['test'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(image_datasets['train'], batch_size=128, shuffle=True, num_workers=2),\n",
        "    'test': DataLoader(image_datasets['test'], batch_size=128, shuffle=False, num_workers=2)\n",
        "}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "print(f\"Số lớp (NUM_CLASSES): {NUM_CLASSES}\")\n",
        "print(f\"Kích thước tập huấn luyện: {dataset_sizes['train']}\")\n",
        "print(f\"Kích thước tập test: {dataset_sizes['test']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h7Sk5q_k9Of",
        "outputId": "0c61a3c7-e3e7-46bf-85a8-6e52ec454d01"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lớp (NUM_CLASSES): 21\n",
            "Kích thước tập huấn luyện: 10044\n",
            "Kích thước tập test: 6682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=21):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n",
        "\n",
        "        self.maxpool_custom = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, s))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.maxpool_custom(out)\n",
        "\n",
        "        out = self.layer2(out)\n",
        "        out = self.maxpool_custom(out)\n",
        "\n",
        "        out = self.layer3(out)\n",
        "        out = self.maxpool_custom(out)\n",
        "\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "_IB6o2UDk-pq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")\n",
        "\n",
        "model = ResNet18(BasicBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "for epoch in range(25):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in dataloaders['train']:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['train']\n",
        "    print(f'Epoch [{epoch+1}/{25}], Train Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Learning Rate hiện tại: {scheduler.get_last_lr()[0]:.10f}\")\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Độ chính xác (Accuracy): {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision (Macro): {precision:.4f}\")\n",
        "print(f\"Recall (Macro): {recall:.4f}\")\n",
        "print(f\"F1-score (Macro): {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLjP2UDjlBHJ",
        "outputId": "fcee8b3c-1757-43b4-86c4-e45a53e82c51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Train Loss: 2.6480\n",
            "Learning Rate hiện tại: 0.0010000000\n",
            "Epoch [2/25], Train Loss: 2.2795\n",
            "Learning Rate hiện tại: 0.0010000000\n",
            "Epoch [3/25], Train Loss: 2.1325\n",
            "Learning Rate hiện tại: 0.0010000000\n",
            "Epoch [4/25], Train Loss: 2.0001\n",
            "Learning Rate hiện tại: 0.0010000000\n",
            "Epoch [5/25], Train Loss: 1.9013\n",
            "Learning Rate hiện tại: 0.0005000000\n",
            "Epoch [6/25], Train Loss: 1.7178\n",
            "Learning Rate hiện tại: 0.0005000000\n",
            "Epoch [7/25], Train Loss: 1.6351\n",
            "Learning Rate hiện tại: 0.0005000000\n",
            "Epoch [8/25], Train Loss: 1.5827\n",
            "Learning Rate hiện tại: 0.0005000000\n",
            "Epoch [9/25], Train Loss: 1.5281\n",
            "Learning Rate hiện tại: 0.0005000000\n",
            "Epoch [10/25], Train Loss: 1.4444\n",
            "Learning Rate hiện tại: 0.0002500000\n",
            "Epoch [11/25], Train Loss: 1.3307\n",
            "Learning Rate hiện tại: 0.0002500000\n",
            "Epoch [12/25], Train Loss: 1.2688\n",
            "Learning Rate hiện tại: 0.0002500000\n",
            "Epoch [13/25], Train Loss: 1.2425\n",
            "Learning Rate hiện tại: 0.0002500000\n",
            "Epoch [14/25], Train Loss: 1.1965\n",
            "Learning Rate hiện tại: 0.0002500000\n",
            "Epoch [15/25], Train Loss: 1.1705\n",
            "Learning Rate hiện tại: 0.0001250000\n",
            "Epoch [16/25], Train Loss: 1.0675\n",
            "Learning Rate hiện tại: 0.0001250000\n",
            "Epoch [17/25], Train Loss: 1.0248\n",
            "Learning Rate hiện tại: 0.0001250000\n",
            "Epoch [18/25], Train Loss: 1.0065\n",
            "Learning Rate hiện tại: 0.0001250000\n",
            "Epoch [19/25], Train Loss: 0.9956\n",
            "Learning Rate hiện tại: 0.0001250000\n",
            "Epoch [20/25], Train Loss: 0.9611\n",
            "Learning Rate hiện tại: 0.0000625000\n",
            "Epoch [21/25], Train Loss: 0.9174\n",
            "Learning Rate hiện tại: 0.0000625000\n",
            "Epoch [22/25], Train Loss: 0.8783\n",
            "Learning Rate hiện tại: 0.0000625000\n",
            "Epoch [23/25], Train Loss: 0.8578\n",
            "Learning Rate hiện tại: 0.0000625000\n",
            "Epoch [24/25], Train Loss: 0.8567\n",
            "Learning Rate hiện tại: 0.0000625000\n",
            "Epoch [25/25], Train Loss: 0.8165\n",
            "Learning Rate hiện tại: 0.0000312500\n",
            "Độ chính xác (Accuracy): 65.56%\n",
            "Precision (Macro): 0.6677\n",
            "Recall (Macro): 0.6556\n",
            "F1-score (Macro): 0.6557\n"
          ]
        }
      ]
    }
  ]
}